profile: dev
server_host: 0.0.0.0
server_rest_port: 5000

db:
  host: localhost
  port: 5432
  database: rag_server
  username:
  password:
  migrations: ./migrations

telegram:
  enabled: false
  bot_token: ""
  mode: "polling"  # "polling" или "webhook"

gpt:
  api_key: ""
  model: ""
  base_url: ""

qdrant:
  host: "localhost"
  port: 6333
  api_key: ""

embeddings:
  model: "text-embedding-3-small"
  base_url: "https://caila.io/api/adapters/openai"
  api_key: ""

openai:
  base_url: "https://api.openai.com/v1"
  api_key: ""
  proxy: ""
  model: "gpt-4o-mini"
  max_tokens: 16000
  temperature: 0.0

prompts:
  prompts_dir: "prompts"
  system_prompt_file: "system_prompt.txt"

execution:
  logs_dir: "./logs"
  reports_dir: "./reports"
  max_clarifications: 3
  max_iterations: 10
  mcp_context_limit: 15000

search:
  max_results: 5
  tavily_api_key: ""
  tavily_api_base_url: "https://api.tavily.com"
  max_searches: 4
  content_limit: 1500

mcp:
  context_limit: 10000
  mcpServers: {}

scraping:
  content_limit: 5000

agents: {}

logging:
  app_name: rag_server
  graylog:
    enabled: false
    host: localhost
    port: 12201
    udp: true
  grafana:
    enabled: false
    url: http://localhost:3100/loki/api/v1/push
    username: ""
    password: ""
    labels:
      service: rag_server
      environment: dev
  console:
    enabled: true
  root_level: INFO
  levels:
    httpx: WARN
    openai: WARN
    uvicorn.access: WARN
    VastController: DEBUG
